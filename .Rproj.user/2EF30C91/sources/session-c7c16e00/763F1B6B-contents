# Setup Environment (assuming necessary packages are loaded: tidyverse, readxl, plyr, dplyr)
library(tidyverse) 
library(readxl) 
library(plyr) 
library(dplyr) 

# Set working directory (as defined in the sources)setwd("C:/Users/zach/OneDrive - North Carolina State University/TVLR/Looming_Sounds_Contrast/Patrick's Work/ZMR_Test") [7, 8]

# 1. Load Data
exp_data = read_excel('ori_con_full.xlsx') [7, 8]

# 2. Initial Data Cleaning and Renaming (CRITICAL CORRECTION)
# Column renaming must be done by index [1, 2]
colnames(exp_data)[1]="id" 
colnames(exp_data)[5]="sound" 
colnames(exp_data)[6]="sig_str" 
colnames(exp_data)[7]="correct" 

# Remove practice trials
exp_data = subset(exp_data, exp_data$sound!='placeholder') [1, 2]

# Remove specified "trouble makers" (IDs 1, 4, 6, 7, 10, 11, 12, 21, 22, 27, 28) [4, 9-11]
exp_data = subset(exp_data, exp_data$id != 1) 
exp_data = subset(exp_data, exp_data$id != 4)
exp_data = subset(exp_data, exp_data$id != 6)
exp_data = subset(exp_data, exp_data$id != 7)
exp_data = subset(exp_data, exp_data$id != 10)
exp_data = subset(exp_data, exp_data$id != 11)
exp_data = subset(exp_data, exp_data$id != 12)
exp_data = subset(exp_data, exp_data$id != 21)
exp_data = subset(exp_data, exp_data$id != 22)
exp_data = subset(exp_data, exp_data$id != 27)
exp_data = subset(exp_data, exp_data$id != 28)

# 3. Response Time (RT) Outlier Cleaning
# Log transform RT [12, 13]
exp_data$RT_log = log(exp_data$response_time)

# Calculate mean and SD of log-transformed RT [12, 13]
sd = sd(exp_data$RT_log)
mean = mean(exp_data$RT_log)

# Remove trials with RT outliers (more than 3 SD from the mean of RT_log) [12, 14]
exp_data = subset(exp_data, RT_log > (mean - 3*sd) & RT_log < (mean + 3*sd))

# 4. Create Grouping Variables: stim_loc and difficulty
# Define stimulus location ('foveal' vs. 'peripheral') based on stimulus_direction [15]
exp_data <- exp_data %>%
  mutate(stim_loc = ifelse(stimulus_direction == 0, "Foveal", "Peripheral"))

# Discretize continuous 'sig_str' into 'Low', 'Med', and 'High' difficulty levels [16, 17]
exp_data <- exp_data %>%
  mutate(difficulty = case_when(
    # Contrast Task Cutoffs
    task_type == "contrast" & sig_str <= 0.05 ~ "Low",
    task_type == "contrast" & sig_str > 0.05 & sig_str <= 0.2 ~ "Med",
    task_type == "contrast" & sig_str > 0.2 ~ "High",
    # Orientation Task Cutoffs
    task_type == "orientation" & sig_str <= 0.03 ~ "Low",
    task_type == "orientation" & sig_str > 0.03 & sig_str <= 0.1 ~ "Med",
    task_type == "orientation" & sig_str > 0.1 ~ "High",
    TRUE ~ NA_character_
  ))

# 5. Calculate the Grouped Mean Accuracy (mu_vector_df) [17, 18]
# Group data by sound, stimulus location, and difficulty, and summarize mean accuracy
mu_vector_df <- exp_data %>%
  group_by(sound, stim_loc, difficulty) %>%
  summarise(
    mean_accuracy = mean(correct),
    .groups = 'drop' 
  ) %>%
  # Arrange the output for consistency
  arrange(sound, stim_loc, difficulty) [18]

# 6. Convert the result to the desired vector (mu_vector_acc_calculated) [18]
mu_vector_acc_calculated <- mu_vector_df %>%
  pull(mean_accuracy)

# Print the resulting vector 
print(mu_vector_acc_calculated)